{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ニューラルネットワーク (Step.2) 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# get hog\n",
    "def HOG(img):\n",
    "    # BGR -> Gray\n",
    "    def BGR2GRAY(img):\n",
    "        gray = img[...,2]*0.2126 + img[...,1]*0.7152 + img[...,0]*0.0722\n",
    "        return gray\n",
    "    \n",
    "    def grad_xy(gray):\n",
    "        H,W = gray.shape\n",
    "        \n",
    "        # padding\n",
    "        gray = np.pad(gray, (1,1), 'edge')\n",
    "        \n",
    "        # get grad x\n",
    "        gx = gray[1:1+H, 2:] - gray[1:1+H, :W]\n",
    "        # get grad y\n",
    "        gy = gray[2:, 1:1+W] - gray[:H, 1:1+W]\n",
    "        # replace 0 with\n",
    "        gx[gx==0] = 1e-6\n",
    "        \n",
    "        return gx, gy\n",
    "    \n",
    "    # get magnitude and gradient\n",
    "    def get_MagGrad(gx, gy):\n",
    "        magunitude = np.sqrt(gx**2+gy**2)\n",
    "        gradient = np.arctan(gy/gx)\n",
    "        \n",
    "        gradient[gradient<0] = gradient[gradient<0] + np.pi\n",
    "        \n",
    "        return magunitude, gradient\n",
    "    \n",
    "    # gradient histogram\n",
    "    def quantization(gradient):\n",
    "        # prepare quantization table\n",
    "        gradient_quantized = np.zeros_like(gradient, dtype=np.int)\n",
    "        \n",
    "        # quantization base\n",
    "        d = np.pi/9  # 20度\n",
    "        \n",
    "        # quantization\n",
    "        for i in range(9):\n",
    "            gradient_quantized[np.where((gradient>=i*d)&(gradient<(i+1)*d))] = i\n",
    "            \n",
    "        return gradient_quantized\n",
    "    \n",
    "    # get gradient histogram\n",
    "    def gradient_histogram(gradient_quantized, magunitude, N=8):\n",
    "        # get shape\n",
    "        H,W = magunitude.shape\n",
    "        \n",
    "        # get cell num\n",
    "        cell_N_H = H//N\n",
    "        cell_N_W = W//N\n",
    "        histogram = np.zeros((cell_N_H, cell_N_W, 9), dtype=np.float32)\n",
    "        \n",
    "        # each pixel\n",
    "        for y in range(cell_N_H):\n",
    "            for x in range(cell_N_W):\n",
    "                for j in range(N):\n",
    "                    for i in range(N):\n",
    "                        histogram[y,x,gradient_quantized[y*N+j, x*N+i]] += magunitude[y*N+j, x*N+i]\n",
    "        \n",
    "        return histogram\n",
    "    \n",
    "    # histogram normalization\n",
    "    def normalization(histogram, C=3, epsilon=1):\n",
    "        cell_N_H, cell_N_W, _ = histogram.shape\n",
    "        # each histogram\n",
    "        for y in range(cell_N_H):\n",
    "            for x in range(cell_N_W):\n",
    "                histogram[y,x] /= np.sqrt(np.sum(histogram[max(y-1, 0):min(y+2, cell_N_H), \n",
    "                                                          max(x-1, 0):min(x+2, cell_N_W)]**2) + epsilon)\n",
    "                \n",
    "        return histogram\n",
    "    \n",
    "    gray = BGR2GRAY(img)\n",
    "    gx, gy = grad_xy(gray)\n",
    "    magunitude, gradient = get_MagGrad(gx, gy)\n",
    "    gradient_quantized = quantization(gradient)\n",
    "    histogram = gradient_histogram(gradient_quantized, magunitude, N=8)\n",
    "    histogram = normalization(histogram, C=3, epsilon=1)\n",
    "    \n",
    "    return histogram\n",
    "\n",
    "# get IoU overlap ratio\n",
    "def iou(a,b):\n",
    "    area_a = (a[2] - a[0])*(a[3] - a[1])\n",
    "    area_b = (b[2] - b[0])*(b[3] - b[1])\n",
    "    \n",
    "    # get top left\n",
    "    iou_x1 = np.maximum(a[0], b[0])\n",
    "    iou_y1 = np.maximum(a[1], b[1])\n",
    "    iou_x2 = np.minimum(a[2], b[2])\n",
    "    iou_y2 = np.minimum(a[3], b[3])\n",
    "    \n",
    "    iou_h = iou_x2 - iou_x1\n",
    "    iou_w = iou_y2 - iou_y1\n",
    "    \n",
    "    if (iou_h<0) or (iou_w<0):\n",
    "        return 0.0\n",
    "    \n",
    "    area_iou = iou_h*iou_w\n",
    "    \n",
    "    iou = area_iou / (area_a + area_b - area_iou)\n",
    "    \n",
    "    return iou\n",
    "\n",
    "# resize using bi-linear\n",
    "def resize(img, h,  w):\n",
    "    # get shape\n",
    "    _h,_w,_c = img.shape\n",
    "    \n",
    "    # get resize ratio\n",
    "    ah = 1.*h/_h\n",
    "    aw = 1.*w/_w\n",
    "    \n",
    "    # get index of each y \n",
    "    y = np.arange(h).repeat(w).reshape(w, -1)\n",
    "    x = np.tile(np.arange(w), (h,1))\n",
    "    \n",
    "    # get coordinate toward x and y of resize image\n",
    "    y = (y/ah)\n",
    "    x = (x/aw)\n",
    "    \n",
    "    # transfer to int\n",
    "    ix = np.floor(x).astype(np.int32)\n",
    "    iy = np.floor(y).astype(np.int32)\n",
    "    \n",
    "    # clip index\n",
    "    ix = np.minimum(ix, _w-2)\n",
    "    iy = np.minimum(iy, _h-2)\n",
    "    \n",
    "    # get distance between original image and resized image index\n",
    "    dx = x -ix\n",
    "    dy = y - ix\n",
    "    \n",
    "    dx = np.tile(dx, [_c, 1, 1]).transpose(1,2,0)\n",
    "    dy = np.tile(dy, [_c, 1, 1]).transpose(1,2,0)\n",
    "    \n",
    "    # resize\n",
    "    out = (1-dx) * (1-dy) *img[iy,ix] + dx *(1-dy) *img[iy, ix+1] + (1-dx) * dy * img[iy+1, ix] + dx*dy*img[iy+1, ix+1]               \n",
    "    out[out>255] = 255\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "class NN:\n",
    "    def __init__(self, ind=2, w=64, w2=64, outd=1, lr=0.1):\n",
    "        self.w1= np.random.normal(0,1, [ind,w])  # 平均０分散１で ind * w　のサイズの行列\n",
    "        self.b1 = np.random.normal(0,1,[w])\n",
    "        self.w2 = np.random.normal(0,1, [w,w2])\n",
    "        self.b2 = np.random.normal(0,1, [w2])\n",
    "        self.wout = np.random.normal(0,1,[w2,outd])  \n",
    "        self.bout = np.random.normal(0,1,[outd])\n",
    "        self.lr = lr\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.z1 = x\n",
    "        self.z2 = sigmoid(np.dot(self.z1, self.w1) + self.b1)\n",
    "        self.z3 = sigmoid(np.dot(self.z2, self.w2) + self.b2)\n",
    "        self.out = sigmoid(np.dot(self.z3, self.wout) + self.bout)\n",
    "        return self.out\n",
    "    \n",
    "    def train(self, x, t):\n",
    "        # backpropagation outer layer\n",
    "        # En = t*np.log(self.out) + (1-t) * np.log(1-self.out)\n",
    "        En = (self.out - t)*self.out*(1-self.out)  # 何故この四季になるのかわからない\n",
    "        grad_En = En\n",
    "        grad_wout = np.dot(self.z3.T, En)\n",
    "        grad_bout = np.dot(np.ones([En.shape[0]]), En)\n",
    "        # update weight and bias\n",
    "        self.wout -= self.lr * grad_wout  # np.expand_dims (grad_wout, axis=-1)\n",
    "        self.bout -= self.lr*grad_bout\n",
    "        \n",
    "        # backpropaagation inter layer\n",
    "        # get gradients for  weifht and bias\n",
    "        grad_u2 = np.dot(En, self.wout.T)*self.z3*(1-self.z3)\n",
    "        grad_w2 = np.dot(self.z2.T, grad_u2)\n",
    "        grad_b2 = np.dot(np.ones([grad_u2.shape[0]]), grad_u2)\n",
    "        # update weight and bias \n",
    "        self.w2 -= self.lr*grad_w2\n",
    "        self.b2 -= self.lr*grad_b2\n",
    "        \n",
    "        # get gradients for  inter layer\n",
    "        grad_u1 = np.dot(grad_u2, self.w2.T)*self.z2*(1-self.z2)\n",
    "        grad_w1 = np.dot(self.z1.T, grad_u1)\n",
    "        grad_b1 = np.dot(np.ones([grad_u1.shape[0]]), grad_u1)\n",
    "        self.w1 -= self.lr*grad_w1\n",
    "        self.b1 -= self.lr*grad_b1\n",
    "        \n",
    "def sigmoid(x):\n",
    "    return 1./ (1.+ np.exp(-x))\n",
    "\n",
    "\n",
    "def train_nn(nn, test_x, test_t, iteration_N=5000):\n",
    "    for i in range(iteration_N):\n",
    "        nn.forward(train_x)\n",
    "        nn.train(train_x, train_t)\n",
    "    return nn  # モデルを返す\n",
    "\n",
    "def test_nn(nn, test_x, test_t, pred_th=0.5):\n",
    "    accuracy_N = 0.\n",
    "    \n",
    "    for data, t in zip(test_x, test_t):\n",
    "        # get prediction\n",
    "        prob = nn.forward(data)\n",
    "        \n",
    "        # count accuracy\n",
    "        pred = 1 if prob>=pred_th else 0\n",
    "        if t==pred:\n",
    "            accuracy_N += 1\n",
    "            \n",
    "    # get accuracy\n",
    "    accuracy = accuracy_N / len(db)  # ここはlen(test_x)でいいのでは？\n",
    "    print('Accuracy >> {} ({}/{})'.format(accuracy, accuracy_N, len(db)))\n",
    "    \n",
    "    \n",
    "# crop bounding box and make dataset\n",
    "def make_dataset(img, gt, Crop_N=200, L=60, th=0.5, H_size=32):\n",
    "    # get shape\n",
    "    H,W,_ = img.shape\n",
    "    \n",
    "    # get HOG feature dimension\n",
    "    HOG_feature_N = ((H_size//8)**2)*9\n",
    "    \n",
    "    # prepare database\n",
    "    db = np.zeros([Crop_N, HOG_feature_N+1])\n",
    "    \n",
    "    # each crop\n",
    "    for i in range(Crop_N):\n",
    "        x1 = np.random.randint(W-L)\n",
    "        y1 = np.random.randint(H-L)\n",
    "        x2 = x1+L\n",
    "        y2 = y1+L\n",
    "        \n",
    "        crop = np.array((x1, y1, x2,y2))\n",
    "        \n",
    "        _iou = np.zeros((3,))\n",
    "        _iou[0] = iou(gt, crop)\n",
    "        \n",
    "        # get label\n",
    "        if _iou.max() >= th:\n",
    "            cv2.rectangle(img, (x1,y1),(x2, y2),(0,0,255), 1)\n",
    "            label =1\n",
    "        else:\n",
    "            cv2.rectangle(img, (x1,y1), (x2,y2), (255,0,0), 1)\n",
    "            label = 0\n",
    "            \n",
    "            \n",
    "        # crop area\n",
    "        crop_area = img[y1:y2, x1:x2]\n",
    "        \n",
    "        # resize crop area\n",
    "        crop_area = resize(crop_area, H_size, H_size)\n",
    "        \n",
    "        # get HOG feature\n",
    "        _hog = HOG(crop_area)\n",
    "        \n",
    "        # store HOG feature and label\n",
    "        db[i,:HOG_feature_N] = _hog.ravel()\n",
    "        db[i, -1] = label\n",
    "        \n",
    "    return db\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (200,) and (144,64) not aligned: 200 (dim 0) != 144 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-00936427d31d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration_N\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtest_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-0f9bc87315ed>\u001b[0m in \u001b[0;36mtrain_nn\u001b[0;34m(nn, test_x, test_t, iteration_N)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration_N\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration_N\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m  \u001b[0;31m# モデルを返す\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-0f9bc87315ed>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (200,) and (144,64) not aligned: 200 (dim 0) != 144 (dim 0)"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('../imori.jpg').astype(np.float32)\n",
    "histogram = HOG(img)\n",
    "\n",
    "gt = np.array((47,41,129,103), dtype=np.float32)\n",
    "db = make_dataset(img, gt)\n",
    "\n",
    "input_dim = db.shape[1] -1\n",
    "train_x = db[:, input_dim]\n",
    "train_t = db[:,-1][...,None]\n",
    "\n",
    "nn = NN(ind=input_dim, lr=0.01)\n",
    "nn = train_nn(nn, train_x, train_t, iteration_N=100000)\n",
    "\n",
    "test_nn(nn, train_x, train_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ちょっとどこ違うのかわからない。後で確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy >> 1.0 (200.0 / 200)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "# get HOG\n",
    "def HOG(img):\n",
    "    # Grayscale\n",
    "    def BGR2GRAY(img):\n",
    "        gray = 0.2126 * img[..., 2] + 0.7152 * img[..., 1] + 0.0722 * img[..., 0]\n",
    "        return gray\n",
    "\n",
    "    # Magnitude and gradient\n",
    "    def get_gradXY(gray):\n",
    "        H, W = gray.shape\n",
    "\n",
    "        # padding before grad\n",
    "        gray = np.pad(gray, (1, 1), 'edge')\n",
    "\n",
    "        # get grad x\n",
    "        gx = gray[1:H+1, 2:] - gray[1:H+1, :W]\n",
    "        # get grad y\n",
    "        gy = gray[2:, 1:W+1] - gray[:H, 1:W+1]\n",
    "        # replace 0 with \n",
    "        gx[gx == 0] = 1e-6\n",
    "\n",
    "        return gx, gy\n",
    "\n",
    "    # get magnitude and gradient\n",
    "    def get_MagGrad(gx, gy):\n",
    "        # get gradient maginitude\n",
    "        magnitude = np.sqrt(gx ** 2 + gy ** 2)\n",
    "\n",
    "        # get gradient angle\n",
    "        gradient = np.arctan(gy / gx)\n",
    "\n",
    "        gradient[gradient < 0] = np.pi / 2 + gradient[gradient < 0] + np.pi / 2\n",
    "\n",
    "        return magnitude, gradient\n",
    "\n",
    "    # Gradient histogram\n",
    "    def quantization(gradient):\n",
    "        # prepare quantization table\n",
    "        gradient_quantized = np.zeros_like(gradient, dtype=np.int)\n",
    "\n",
    "        # quantization base\n",
    "        d = np.pi / 9\n",
    "\n",
    "        # quantization\n",
    "        for i in range(9):\n",
    "            gradient_quantized[np.where((gradient >= d * i) & (gradient <= d * (i + 1)))] = i\n",
    "\n",
    "        return gradient_quantized\n",
    "\n",
    "\n",
    "    # get gradient histogram\n",
    "    def gradient_histogram(gradient_quantized, magnitude, N=8):\n",
    "        # get shape\n",
    "        H, W = magnitude.shape\n",
    "\n",
    "        # get cell num\n",
    "        cell_N_H = H // N\n",
    "        cell_N_W = W // N\n",
    "        histogram = np.zeros((cell_N_H, cell_N_W, 9), dtype=np.float32)\n",
    "\n",
    "        # each pixel\n",
    "        for y in range(cell_N_H):\n",
    "            for x in range(cell_N_W):\n",
    "                for j in range(N):\n",
    "                    for i in range(N):\n",
    "                        histogram[y, x, gradient_quantized[y * 4 + j, x * 4 + i]] += magnitude[y * 4 + j, x * 4 + i]\n",
    "\n",
    "        return histogram\n",
    "\n",
    "\t\t# histogram normalization\n",
    "    def normalization(histogram, C=3, epsilon=1):\n",
    "        cell_N_H, cell_N_W, _ = histogram.shape\n",
    "        ## each histogram\n",
    "        for y in range(cell_N_H):\n",
    "    \t    for x in range(cell_N_W):\n",
    "       \t    #for i in range(9):\n",
    "                histogram[y, x] /= np.sqrt(np.sum(histogram[max(y - 1, 0) : min(y + 2, cell_N_H),\n",
    "                                                            max(x - 1, 0) : min(x + 2, cell_N_W)] ** 2) + epsilon)\n",
    "\n",
    "        return histogram\n",
    "\n",
    "    # 1. BGR -> Gray\n",
    "    gray = BGR2GRAY(img)\n",
    "\n",
    "    # 1. Gray -> Gradient x and y\n",
    "    gx, gy = get_gradXY(gray)\n",
    "\n",
    "    # 2. get gradient magnitude and angle\n",
    "    magnitude, gradient = get_MagGrad(gx, gy)\n",
    "\n",
    "    # 3. Quantization\n",
    "    gradient_quantized = quantization(gradient)\n",
    "\n",
    "    # 4. Gradient histogram\n",
    "    histogram = gradient_histogram(gradient_quantized, magnitude)\n",
    "    \n",
    "    # 5. Histogram normalization\n",
    "    histogram = normalization(histogram)\n",
    "\n",
    "    return histogram\n",
    "\n",
    "\n",
    "# get IoU overlap ratio\n",
    "def iou(a, b):\n",
    "\t# get area of a\n",
    "    area_a = (a[2] - a[0]) * (a[3] - a[1])\n",
    "\t# get area of b\n",
    "    area_b = (b[2] - b[0]) * (b[3] - b[1])\n",
    "\n",
    "\t# get left top x of IoU\n",
    "    iou_x1 = np.maximum(a[0], b[0])\n",
    "\t# get left top y of IoU\n",
    "    iou_y1 = np.maximum(a[1], b[1])\n",
    "\t# get right bottom of IoU\n",
    "    iou_x2 = np.minimum(a[2], b[2])\n",
    "\t# get right bottom of IoU\n",
    "    iou_y2 = np.minimum(a[3], b[3])\n",
    "\n",
    "\t# get width of IoU\n",
    "    iou_w = iou_x2 - iou_x1\n",
    "\t# get height of IoU\n",
    "    iou_h = iou_y2 - iou_y1\n",
    "\n",
    "\t# get area of IoU\n",
    "    area_iou = iou_w * iou_h\n",
    "\t# get overlap ratio between IoU and all area\n",
    "    iou = area_iou / (area_a + area_b - area_iou)\n",
    "\n",
    "    return iou\n",
    "\n",
    "# resize using bi-linear\n",
    "def resize(img, h, w):\n",
    "    # get shape\n",
    "    _h, _w, _c  = img.shape\n",
    "\n",
    "    # get resize ratio\n",
    "    ah = 1. * h / _h\n",
    "    aw = 1. * w / _w\n",
    "\n",
    "    # get index of each y\n",
    "    y = np.arange(h).repeat(w).reshape(w, -1)\n",
    "    # get index of each x\n",
    "    x = np.tile(np.arange(w), (h, 1))\n",
    "\n",
    "    # get coordinate toward x and y of resized image\n",
    "    y = (y / ah)\n",
    "    x = (x / aw)\n",
    "\n",
    "    # transfer to int\n",
    "    ix = np.floor(x).astype(np.int32)\n",
    "    iy = np.floor(y).astype(np.int32)\n",
    "\n",
    "    # clip index\n",
    "    ix = np.minimum(ix, _w-2)\n",
    "    iy = np.minimum(iy, _h-2)\n",
    "\n",
    "    # get distance between original image index and resized image index\n",
    "    dx = x - ix\n",
    "    dy = y - iy\n",
    "\n",
    "    dx = np.tile(dx, [_c, 1, 1]).transpose(1, 2, 0)\n",
    "    dy = np.tile(dy, [_c, 1, 1]).transpose(1, 2, 0)\n",
    "    \n",
    "    # resize\n",
    "    out = (1 - dx) * (1 - dy) * img[iy, ix] + dx * (1 - dy) * img[iy, ix + 1] + (1 - dx) * dy * img[iy + 1, ix] + dx * dy * img[iy + 1, ix + 1]\n",
    "    out[out > 255] = 255\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# neural network\n",
    "class NN:\n",
    "    def __init__(self, ind=2, w=64, w2=64, outd=1, lr=0.1):\n",
    "        # layer 1 weight\n",
    "        self.w1 = np.random.normal(0, 1, [ind, w])\n",
    "        # layer 1 bias\n",
    "        self.b1 = np.random.normal(0, 1, [w])\n",
    "        # layer 2 weight\n",
    "        self.w2 = np.random.normal(0, 1, [w, w2])\n",
    "        # layer 2 bias\n",
    "        self.b2 = np.random.normal(0, 1, [w2])\n",
    "        # output layer weight\n",
    "        self.wout = np.random.normal(0, 1, [w2, outd])\n",
    "        # output layer bias\n",
    "        self.bout = np.random.normal(0, 1, [outd])\n",
    "        # learning rate\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input tensor\n",
    "        self.z1 = x\n",
    "        # layer 1 output tensor\n",
    "        self.z2 = sigmoid(np.dot(self.z1, self.w1) + self.b1)\n",
    "        # layer 2 output tensor\n",
    "        self.z3 = sigmoid(np.dot(self.z2, self.w2) + self.b2)\n",
    "        # output layer tensor\n",
    "        self.out = sigmoid(np.dot(self.z3, self.wout) + self.bout)\n",
    "        return self.out\n",
    "\n",
    "    def train(self, x, t):\n",
    "        # backpropagation output layer\n",
    "        #En = t * np.log(self.out) + (1-t) * np.log(1-self.out)\n",
    "        En = (self.out - t) * self.out * (1 - self.out)\n",
    "        # get gradients for weight and bias\n",
    "        grad_wout = np.dot(self.z3.T, En)\n",
    "        grad_bout = np.dot(np.ones([En.shape[0]]), En)\n",
    "        # update weight and bias\n",
    "        self.wout -= self.lr * grad_wout\n",
    "        self.bout -= self.lr * grad_bout\n",
    "\n",
    "        # backpropagation inter layer\n",
    "        # get gradients for weight and bias\n",
    "        grad_u2 = np.dot(En, self.wout.T) * self.z3 * (1 - self.z3)\n",
    "        grad_w2 = np.dot(self.z2.T, grad_u2)\n",
    "        grad_b2 = np.dot(np.ones([grad_u2.shape[0]]), grad_u2)\n",
    "        # update weight and bias\n",
    "        self.w2 -= self.lr * grad_w2\n",
    "        self.b2 -= self.lr * grad_b2\n",
    "        \n",
    "        # get gradients for weight and bias\n",
    "        grad_u1 = np.dot(grad_u2, self.w2.T) * self.z2 * (1 - self.z2)\n",
    "        grad_w1 = np.dot(self.z1.T, grad_u1)\n",
    "        grad_b1 = np.dot(np.ones([grad_u1.shape[0]]), grad_u1)\n",
    "        # update weight and bias\n",
    "        self.w1 -= self.lr * grad_w1\n",
    "        self.b1 -= self.lr * grad_b1\n",
    "\n",
    "# sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "# train\n",
    "def train_nn(nn, train_x, train_t, iteration_N=10000):\n",
    "    # each iteration\n",
    "    for i in range(iteration_N):\n",
    "        # feed-forward data\n",
    "        nn.forward(train_x)\n",
    "        # update parameter\n",
    "        nn.train(train_x, train_t)\n",
    "\n",
    "    return nn\n",
    "\n",
    "# test\n",
    "def test_nn(nn, test_x, test_t, pred_th=0.5):\n",
    "    accuracy_N = 0.\n",
    "\n",
    "    # each data\n",
    "    for data, t in zip(test_x, test_t):\n",
    "        # get prediction\n",
    "        prob = nn.forward(data)\n",
    "\n",
    "        # count accuracy\n",
    "        pred = 1 if prob >= pred_th else 0\n",
    "        if t == pred:\n",
    "            accuracy_N += 1\n",
    "\n",
    "    # get accuracy \n",
    "    accuracy = accuracy_N / len(db)\n",
    "\n",
    "    print(\"Accuracy >> {} ({} / {})\".format(accuracy, accuracy_N, len(db)))\n",
    "\n",
    "\n",
    "# crop bounding box and make dataset\n",
    "def make_dataset(img, gt, Crop_N=200, L=60, th=0.5, H_size=32):\n",
    "    # get shape\n",
    "    H, W, _ = img.shape\n",
    "\n",
    "    # get HOG feature dimension\n",
    "    HOG_feature_N = ((H_size // 8) ** 2) * 9\n",
    "\n",
    "    # prepare database\n",
    "    db = np.zeros([Crop_N, HOG_feature_N + 1])\n",
    "\n",
    "    # each crop\n",
    "    for i in range(Crop_N):\n",
    "        # get left top x of crop bounding box\n",
    "        x1 = np.random.randint(W - L)\n",
    "        # get left top y of crop bounding box\n",
    "        y1 = np.random.randint(H - L)\n",
    "        # get right bottom x of crop bounding box\n",
    "        x2 = x1 + L\n",
    "        # get right bottom y of crop bounding box\n",
    "        y2 = y1 + L\n",
    "\n",
    "        # get bounding box\n",
    "        crop = np.array((x1, y1, x2, y2))\n",
    "\n",
    "        _iou = np.zeros((3,))\n",
    "        _iou[0] = iou(gt, crop)\n",
    "        #_iou[1] = iou(gt2, crop)\n",
    "        #_iou[2] = iou(gt3, crop)\n",
    "\n",
    "        # get label\n",
    "        if _iou.max() >= th:\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0,0,255), 1)\n",
    "            label = 1\n",
    "        else:\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255,0,0), 1)\n",
    "            label = 0\n",
    "\n",
    "        # crop area\n",
    "        crop_area = img[y1:y2, x1:x2]\n",
    "\n",
    "        # resize crop area\n",
    "        crop_area = resize(crop_area, H_size, H_size)\n",
    "\n",
    "        # get HOG feature\n",
    "        _hog = HOG(crop_area)\n",
    "        \n",
    "        # store HOG feature and label\n",
    "        db[i, :HOG_feature_N] = _hog.ravel()\n",
    "        db[i, -1] = label\n",
    "\n",
    "    return db\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"../imori.jpg\").astype(np.float32)\n",
    "\n",
    "# get HOG\n",
    "histogram = HOG(img)\n",
    "\n",
    "# prepare gt bounding box\n",
    "gt = np.array((47, 41, 129, 103), dtype=np.float32)\n",
    "\n",
    "# get database\n",
    "db = make_dataset(img, gt)\n",
    "\n",
    "\n",
    "# train neural network\n",
    "# get input feature dimension\n",
    "input_dim = db.shape[1] - 1\n",
    "# prepare train data X\n",
    "train_x = db[:, :input_dim]\n",
    "# prepare train data t\n",
    "train_t = db[:, -1][..., None]\n",
    "\n",
    "# prepare neural network\n",
    "nn = NN(ind=input_dim, lr=0.01)\n",
    "# training\n",
    "nn = train_nn(nn, train_x, train_t, iteration_N=10000)\n",
    "\n",
    "# test\n",
    "test_nn(nn, train_x, train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
